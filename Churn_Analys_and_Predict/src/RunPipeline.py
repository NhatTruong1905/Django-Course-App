import sys
import logging
from . import DataPreprocessor, ModelTrainer, DataVisualizer, IOHandler

class Pipeline:
    """
    Class quáº£n lÃ½ toÃ n bá»™ quy trÃ¬nh E-commerce Churn Prediction.
    ÄÃ³ng gÃ³i logic xá»­ lÃ½ Ä‘á»ƒ main.py gá»i gá»n gÃ ng.
    """
    def __init__(self, config, logger):
        self.config = config
        self.logger = logger
        self.preprocessor = None
        self.trainer = None

    def run_eda(self):
        """Cháº¡y phÃ¢n tÃ­ch dá»¯ liá»‡u khÃ¡m phÃ¡ (EDA)"""
        self.logger.info("\n" + "="*70)
        self.logger.info("EXPLORATORY DATA ANALYSIS")
        self.logger.info("="*70)

        # Load raw data
        data_path = self.config['data']['raw_path']
        self.logger.info(f"Loading data for EDA from: {data_path}")
        df = IOHandler.read_data(data_path)

        # Visualize
        visualizer = DataVisualizer(self.config, self.logger)
        
        self.logger.info("Plotting missing values...")
        visualizer.plot_missing_values(df)
        
        self.logger.info("Plotting target distribution...")
        visualizer.plot_target_distribution(df['Churn'])
        
        self.logger.info("Plotting correlation matrix...")
        visualizer.plot_correlation_matrix(df)
        
        self.logger.info("EDA completed!")

    def run_preprocessing(self):
        """Cháº¡y quy trÃ¬nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u"""
        self.logger.info("\n" + "="*70)
        self.logger.info("STAGE 1: DATA PREPROCESSING")
        self.logger.info("="*70)
        
        # Initialize
        self.preprocessor = DataPreprocessor(self.config['preprocessing'], self.logger)
        
        # Load data
        data_path = self.config['data']['raw_path']
        self.logger.info(f"Loading data from: {data_path}")
        
        # Handle Excel logic inside pipeline (cleaner main)
        if data_path.endswith(('.xlsx', '.xls')):
            sheet_name = self.config['data'].get('sheet_name', 0)
            df = self.preprocessor.load_data(data_path, sheet_name=sheet_name)
        else:
            df = self.preprocessor.load_data(data_path)
        
        # Transform
        X, y = self.preprocessor.fit_transform(df, target_col='Churn')
        
        # Save processed data
        processed_path = self.config['data']['processed_path']
        processed_df = X.copy()
        processed_df['Churn'] = y
        IOHandler.save_data(processed_df, processed_path)
        self.logger.info(f"Processed data saved to: {processed_path}")
        
        return X, y

    def run_training(self, X, y, optimize=True):
        """Cháº¡y quy trÃ¬nh huáº¥n luyá»‡n"""
        self.logger.info("STAGE 2: MODEL TRAINING & OPTIMIZATION")
        
        self.trainer = ModelTrainer(self.config, self.logger)
        self.trainer.load_data(X, y)
        self.trainer.split_data()
        
        # Train
        metrics = self.trainer.train_all_models(optimize=optimize)
        
        # Save artifacts
        model_path = self.trainer.save_model()
        self.logger.info(f"\nBest model saved to: {model_path}")
        
        results_path = self.trainer.save_results()
        self.logger.info(f"Results saved to: {results_path}")
        
        return self.trainer, metrics

    def run_visualization(self, trainer, metrics):
        """Cháº¡y quy trÃ¬nh váº½ biá»ƒu Ä‘á»“ bÃ¡o cÃ¡o (ÄÃ£ fix lá»—i tham sá»‘)"""
        self.logger.info("STAGE 3: VISUALIZATION & ANALYSIS")

        visualizer = DataVisualizer(self.config, self.logger)

        # 1. Comparison
        # FIX: ThÃªm metric_names vÃ o
        metric_names = ['accuracy', 'f1', 'precision', 'recall', 'roc_auc']
        visualizer.plot_model_comparison(metrics, metric_names)

        # 2. Confusion Matrix
        for model_name, result in trainer.results.items():
            cm = result['confusion_matrix']
            # FIX: ThÃªm labels=[0, 1] vÃ  XÃ“A save_name (vÃ¬ hÃ m khÃ´ng nháº­n tham sá»‘ nÃ y)
            visualizer.plot_confusion_matrix(
                cm,
                labels=[0, 1],
                title=f'Confusion Matrix - {model_name.upper()}'
            )

        # 3. ROC Curve
        # FIX: Láº¥y dá»¯ liá»‡u roc_curve_data Ä‘Ã£ tÃ­nh á»Ÿ ModelTrainer ra
        roc_results = {}
        for model_name, result in trainer.results.items():
            # Kiá»ƒm tra xem ModelTrainer Ä‘Ã£ tÃ­nh ROC chÆ°a
            if result.get('roc_curve_data') is not None:
                roc_results[model_name] = result['roc_curve_data']

        if roc_results:
            visualizer.plot_roc_curve(roc_results)

        # 4. Feature Importance (Best Model)
        if self.config.get('evaluation', {}).get('feature_importance', True):
            importance_df = trainer.get_feature_importance()
            if importance_df is not None:
                # FIX: ThÃªm top_n=20 vÃ  XÃ“A title, save_name (hÃ m tá»± xá»­ lÃ½)
                visualizer.plot_feature_importance(
                    importance_df,
                    top_n=20
                )

        self.logger.info("Visualization completed!")

    def load_processed_data(self):
        """HÃ m phá»¥ trá»£ Ä‘á»ƒ load data Ä‘Ã£ xá»­ lÃ½ (dÃ¹ng cho mode train riÃªng láº»)"""
        processed_path = self.config['data']['processed_path']
        self.logger.info(f"Loading processed data from: {processed_path}")
        df = IOHandler.read_data(processed_path)
        X = df.drop(columns=['Churn'])
        y = df['Churn']
        return X, y



if __name__ == "__main__":
    import pandas as pd
    import numpy as np
    import shutil
    import os
    # VÃ¬ cháº¡y trá»±c tiáº¿p file nÃ y, ta cáº§n config giáº£ láº­p
    print("\n" + "=" * 50)
    print("ğŸ§ª TESTING PIPELINE FLOW (MOCK DATA)")
    print("=" * 50)

    # 1. Táº¡o Config Giáº£ (Mock Config)
    # LÆ°u táº¡m vÃ o thÆ° má»¥c test_output Ä‘á»ƒ khÃ´ng áº£nh hÆ°á»Ÿng folder tháº­t
    test_config = {
        'data': {
            'raw_path': 'test_raw_dummy.csv',
            'processed_path': 'test_output/processed_dummy.csv',
            'target_col': 'Churn',
            'test_size': 0.2,
            'random_state': 42
        },
        'preprocessing': {
            'missing_strategy': {'numerical': 'median', 'categorical': 'mode'},
            'feature_selection': False,
            'scaler_type': 'standard',
            'categorical_encoding': 'label'
        },
        'models': {
            # Test vá»›i model nháº¹ nháº¥t Ä‘á»ƒ cháº¡y nhanh
            'random_forest': {'n_estimators': 5, 'max_depth': 3}
        },
        'tuning': {
            'cv_folds': 2,  # Fold Ã­t thÃ´i cho nhanh
            'scoring': 'accuracy'
        },
        'evaluation': {
            'feature_importance': True
        },
        'artifacts': {
            'logs_dir': 'test_output/logs',
            'models_dir': 'test_output/models',
            'results_dir': 'test_output/results',
            'figures_dir': 'test_output/figures'
        }
    }

    # 2. Táº¡o Dá»¯ liá»‡u Giáº£ (Mock Data)
    print("1. Generating dummy data...")
    df_dummy = pd.DataFrame({
        'Tenure': np.random.randint(1, 20, 50),
        'CityTier': np.random.choice([1, 2, 3], 50),
        'WarehouseToHome': np.random.randint(5, 35, 50),
        'Gender': np.random.choice(['Male', 'Female'], 50),
        'Churn': np.random.choice([0, 1], 50)  # Target
    })
    # LÆ°u file giáº£ Ä‘á»ƒ pipeline Ä‘á»c vÃ o (giáº£ vá» nhÆ° file tháº­t)
    df_dummy.to_csv('test_raw_dummy.csv', index=False)

    # 3. Khá»Ÿi táº¡o Pipeline
    # Logger táº¡m
    logger = logging.getLogger("TEST_PIPE")
    logger.setLevel(logging.INFO)
    logger.addHandler(logging.StreamHandler(sys.stdout))

    pipeline = Pipeline(test_config, logger)

    try:
        # 4. Cháº¡y thá»­ cÃ¡c bÆ°á»›c
        print("\n2. Testing Preprocessing...")
        X, y = pipeline.run_preprocessing()
        print(f"   -> OK. Shape: {X.shape}")

        print("\n3. Testing Training (No Optimize)...")
        trainer, metrics = pipeline.run_training(X, y, optimize=False)
        print(f"   -> OK. Metrics: {metrics}")

        print("\n4. Testing Visualization...")
        pipeline.run_visualization(trainer, metrics)
        print("   -> OK. Plots saved.")

        print("\nâœ… PIPELINE FLOW TEST PASSED!")

    except Exception as e:
        print(f"\TEST FAILED: {e}")
        import traceback

        traceback.print_exc()

    finally:
        # 5. Dá»n dáº¹p rÃ¡c (Clean up)
        print("\n5. Cleaning up test files...")
        if os.path.exists('test_raw_dummy.csv'):
            os.remove('test_raw_dummy.csv')
        if os.path.exists('test_output'):
            shutil.rmtree('test_output')  # XÃ³a thÆ° má»¥c táº¡m
        print("   -> Cleaned.")